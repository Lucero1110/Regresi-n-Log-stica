{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7705b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.special as special \n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "214a2d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>...</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>source</th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_verifications</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>amenities</th>\n",
       "      <th>license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27262</td>\n",
       "      <td>37177</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>37.989240</td>\n",
       "      <td>23.700000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>t</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>Dato desconocido</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Heating - split type ductless system\", \"Dish...</td>\n",
       "      <td>00002433111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>809874</td>\n",
       "      <td>4259738</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.962150</td>\n",
       "      <td>23.721790</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>f</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>Dato desconocido</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Host greets you\", \"Dishes and silverware\", \"...</td>\n",
       "      <td>00001240742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>866381</td>\n",
       "      <td>4551671</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>23.724430</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>t</td>\n",
       "      <td>['email', 'phone', 'work_email']</td>\n",
       "      <td>Dato desconocido</td>\n",
       "      <td>Entire condo</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Coffee\", \"Dishes and silverware\", \"Washer\", ...</td>\n",
       "      <td>00002608390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>886724</td>\n",
       "      <td>4700824</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.997450</td>\n",
       "      <td>23.739730</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Dato desconocido</td>\n",
       "      <td>f</td>\n",
       "      <td>['email']</td>\n",
       "      <td>Athens, Attica, Greece</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Host greets you\", \"Luggage dropoff allowed\",...</td>\n",
       "      <td>00000052101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>896212</td>\n",
       "      <td>4777984</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>37.988440</td>\n",
       "      <td>23.738450</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>t</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>Athens, Attica, Greece</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Host greets you\", \"Coffee\", \"Dishes and silv...</td>\n",
       "      <td>00000206136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>14637</td>\n",
       "      <td>1318251942056598277</td>\n",
       "      <td>25811452</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.979336</td>\n",
       "      <td>23.726354</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-26</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>t</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>Dato desconocido</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Coffee\", \"Dishes and silverware\", \"Washer\", ...</td>\n",
       "      <td>00003108542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>14638</td>\n",
       "      <td>1318276742106864141</td>\n",
       "      <td>666320836</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.992753</td>\n",
       "      <td>23.700000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>f</td>\n",
       "      <td>['phone']</td>\n",
       "      <td>Dato desconocido</td>\n",
       "      <td>Entire condo</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Heating - split type ductless system\", \"Coff...</td>\n",
       "      <td>00002888548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>14639</td>\n",
       "      <td>1318307768558324736</td>\n",
       "      <td>221534605</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>37.983118</td>\n",
       "      <td>23.756604</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>f</td>\n",
       "      <td>['email', 'phone', 'work_email']</td>\n",
       "      <td>Athina, Greece</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"TV\", \"Hair dryer\", \"Refrigerator\", \"Washer \\...</td>\n",
       "      <td>00002764099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14640</th>\n",
       "      <td>14640</td>\n",
       "      <td>1318405788507138933</td>\n",
       "      <td>650411545</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.984651</td>\n",
       "      <td>23.735136</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Dato desconocido</td>\n",
       "      <td>f</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>Dato desconocido</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Coffee\", \"Outlet covers\", \"Washer\", \"Dishes ...</td>\n",
       "      <td>00003072289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14641</th>\n",
       "      <td>14641</td>\n",
       "      <td>1318601800941001079</td>\n",
       "      <td>31290848</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>37.968246</td>\n",
       "      <td>23.726156</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>f</td>\n",
       "      <td>['email', 'phone', 'work_email']</td>\n",
       "      <td>Athina, Greece</td>\n",
       "      <td>Entire condo</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Heating - split type ductless system\", \"Coff...</td>\n",
       "      <td>00003026761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14642 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                   id    host_id  host_response_rate  \\\n",
       "0               0                27262      37177               100.0   \n",
       "1               1               809874    4259738               100.0   \n",
       "2               2               866381    4551671               100.0   \n",
       "3               3               886724    4700824               100.0   \n",
       "4               4               896212    4777984               100.0   \n",
       "...           ...                  ...        ...                 ...   \n",
       "14637       14637  1318251942056598277   25811452               100.0   \n",
       "14638       14638  1318276742106864141  666320836               100.0   \n",
       "14639       14639  1318307768558324736  221534605               100.0   \n",
       "14640       14640  1318405788507138933  650411545               100.0   \n",
       "14641       14641  1318601800941001079   31290848               100.0   \n",
       "\n",
       "       host_acceptance_rate  host_listings_count  host_total_listings_count  \\\n",
       "0                     100.0                  4.0                       12.0   \n",
       "1                      96.0                  2.0                        2.0   \n",
       "2                      97.0                  1.0                        1.0   \n",
       "3                      99.6                  1.0                        1.0   \n",
       "4                     100.0                 29.0                       50.0   \n",
       "...                     ...                  ...                        ...   \n",
       "14637                 100.0                  3.0                        3.0   \n",
       "14638                  99.6                  2.0                        2.0   \n",
       "14639                  98.0                 53.0                       12.5   \n",
       "14640                  99.6                  1.0                        1.0   \n",
       "14641                 100.0                 11.0                       12.5   \n",
       "\n",
       "        latitude  longitude  accommodates  ...  last_scraped       source  \\\n",
       "0      37.989240  23.700000           2.0  ...    2024-12-25  city scrape   \n",
       "1      37.962150  23.721790           4.0  ...    2024-12-25  city scrape   \n",
       "2      38.000000  23.724430           3.0  ...    2024-12-25  city scrape   \n",
       "3      37.997450  23.739730           2.0  ...    2024-12-25  city scrape   \n",
       "4      37.988440  23.738450           2.0  ...    2024-12-25  city scrape   \n",
       "...          ...        ...           ...  ...           ...          ...   \n",
       "14637  37.979336  23.726354           4.0  ...    2024-12-26  city scrape   \n",
       "14638  37.992753  23.700000           2.0  ...    2024-12-25  city scrape   \n",
       "14639  37.983118  23.756604           2.0  ...    2024-12-25  city scrape   \n",
       "14640  37.984651  23.735136           4.0  ...    2024-12-25  city scrape   \n",
       "14641  37.968246  23.726156           3.0  ...    2024-12-25  city scrape   \n",
       "\n",
       "       host_response_time  host_is_superhost  \\\n",
       "0          within an hour                  t   \n",
       "1          within an hour                  f   \n",
       "2      within a few hours                  t   \n",
       "3        Dato desconocido                  f   \n",
       "4          within an hour                  t   \n",
       "...                   ...                ...   \n",
       "14637      within an hour                  t   \n",
       "14638  within a few hours                  f   \n",
       "14639  within a few hours                  f   \n",
       "14640    Dato desconocido                  f   \n",
       "14641      within an hour                  f   \n",
       "\n",
       "                     host_verifications           neighbourhood  \\\n",
       "0                    ['email', 'phone']        Dato desconocido   \n",
       "1                    ['email', 'phone']        Dato desconocido   \n",
       "2      ['email', 'phone', 'work_email']        Dato desconocido   \n",
       "3                             ['email']  Athens, Attica, Greece   \n",
       "4                    ['email', 'phone']  Athens, Attica, Greece   \n",
       "...                                 ...                     ...   \n",
       "14637                ['email', 'phone']        Dato desconocido   \n",
       "14638                         ['phone']        Dato desconocido   \n",
       "14639  ['email', 'phone', 'work_email']          Athina, Greece   \n",
       "14640                ['email', 'phone']        Dato desconocido   \n",
       "14641  ['email', 'phone', 'work_email']          Athina, Greece   \n",
       "\n",
       "            property_type        room_type  \\\n",
       "0      Entire rental unit  Entire home/apt   \n",
       "1      Entire rental unit  Entire home/apt   \n",
       "2            Entire condo  Entire home/apt   \n",
       "3      Entire rental unit  Entire home/apt   \n",
       "4      Entire rental unit  Entire home/apt   \n",
       "...                   ...              ...   \n",
       "14637  Entire rental unit  Entire home/apt   \n",
       "14638        Entire condo  Entire home/apt   \n",
       "14639  Entire rental unit  Entire home/apt   \n",
       "14640  Entire rental unit  Entire home/apt   \n",
       "14641        Entire condo  Entire home/apt   \n",
       "\n",
       "                                               amenities      license  \n",
       "0      [\"Heating - split type ductless system\", \"Dish...  00002433111  \n",
       "1      [\"Host greets you\", \"Dishes and silverware\", \"...  00001240742  \n",
       "2      [\"Coffee\", \"Dishes and silverware\", \"Washer\", ...  00002608390  \n",
       "3      [\"Host greets you\", \"Luggage dropoff allowed\",...  00000052101  \n",
       "4      [\"Host greets you\", \"Coffee\", \"Dishes and silv...  00000206136  \n",
       "...                                                  ...          ...  \n",
       "14637  [\"Coffee\", \"Dishes and silverware\", \"Washer\", ...  00003108542  \n",
       "14638  [\"Heating - split type ductless system\", \"Coff...  00002888548  \n",
       "14639  [\"TV\", \"Hair dryer\", \"Refrigerator\", \"Washer \\...  00002764099  \n",
       "14640  [\"Coffee\", \"Outlet covers\", \"Washer\", \"Dishes ...  00003072289  \n",
       "14641  [\"Heating - split type ductless system\", \"Coff...  00003026761  \n",
       "\n",
       "[14642 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargar archivo csv des seaborn\n",
    "\n",
    "df= pd.read_csv('Datos_Limpios_Athenas_NNNA.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b7b279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14642 entries, 0 to 14641\n",
      "Data columns (total 51 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   Unnamed: 0                                    14642 non-null  int64  \n",
      " 1   id                                            14642 non-null  int64  \n",
      " 2   host_id                                       14642 non-null  int64  \n",
      " 3   host_response_rate                            14642 non-null  float64\n",
      " 4   host_acceptance_rate                          14642 non-null  float64\n",
      " 5   host_listings_count                           14642 non-null  float64\n",
      " 6   host_total_listings_count                     14642 non-null  float64\n",
      " 7   latitude                                      14642 non-null  float64\n",
      " 8   longitude                                     14642 non-null  float64\n",
      " 9   accommodates                                  14642 non-null  float64\n",
      " 10  bathrooms                                     14642 non-null  float64\n",
      " 11  bedrooms                                      14642 non-null  float64\n",
      " 12  beds                                          14642 non-null  float64\n",
      " 13  price                                         14642 non-null  float64\n",
      " 14  minimum_nights                                14642 non-null  float64\n",
      " 15  maximum_nights                                14642 non-null  float64\n",
      " 16  minimum_minimum_nights                        14642 non-null  float64\n",
      " 17  maximum_minimum_nights                        14642 non-null  float64\n",
      " 18  minimum_maximum_nights                        14642 non-null  float64\n",
      " 19  maximum_maximum_nights                        14642 non-null  float64\n",
      " 20  minimum_nights_avg_ntm                        14642 non-null  float64\n",
      " 21  maximum_nights_avg_ntm                        14642 non-null  float64\n",
      " 22  availability_30                               14642 non-null  float64\n",
      " 23  availability_60                               14642 non-null  float64\n",
      " 24  availability_90                               14642 non-null  float64\n",
      " 25  availability_365                              14642 non-null  float64\n",
      " 26  number_of_reviews                             14642 non-null  float64\n",
      " 27  number_of_reviews_ltm                         14642 non-null  float64\n",
      " 28  number_of_reviews_l30d                        14642 non-null  float64\n",
      " 29  review_scores_rating                          14642 non-null  float64\n",
      " 30  review_scores_accuracy                        14642 non-null  float64\n",
      " 31  review_scores_cleanliness                     14642 non-null  float64\n",
      " 32  review_scores_checkin                         14642 non-null  float64\n",
      " 33  review_scores_communication                   14642 non-null  float64\n",
      " 34  review_scores_location                        14642 non-null  float64\n",
      " 35  review_scores_value                           14642 non-null  float64\n",
      " 36  calculated_host_listings_count                14642 non-null  float64\n",
      " 37  calculated_host_listings_count_entire_homes   14642 non-null  float64\n",
      " 38  calculated_host_listings_count_private_rooms  14642 non-null  float64\n",
      " 39  calculated_host_listings_count_shared_rooms   14642 non-null  float64\n",
      " 40  reviews_per_month                             14642 non-null  float64\n",
      " 41  last_scraped                                  14642 non-null  object \n",
      " 42  source                                        14642 non-null  object \n",
      " 43  host_response_time                            14642 non-null  object \n",
      " 44  host_is_superhost                             14642 non-null  object \n",
      " 45  host_verifications                            14642 non-null  object \n",
      " 46  neighbourhood                                 14642 non-null  object \n",
      " 47  property_type                                 14642 non-null  object \n",
      " 48  room_type                                     14642 non-null  object \n",
      " 49  amenities                                     14642 non-null  object \n",
      " 50  license                                       14642 non-null  object \n",
      "dtypes: float64(38), int64(3), object(10)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0726de7e",
   "metadata": {},
   "source": [
    "### Cambio de categorias "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c0aa31",
   "metadata": {},
   "source": [
    "**Primer cambio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fa7850c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dato desconocido' 'a few days or more' 'within a day'\n",
      " 'within a few hours' 'within an hour']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>...</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>source</th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_verifications</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>amenities</th>\n",
       "      <th>license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27262</td>\n",
       "      <td>37177</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>37.989240</td>\n",
       "      <td>23.700000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Less than a day</td>\n",
       "      <td>t</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>Dato desconocido</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Heating - split type ductless system\", \"Dish...</td>\n",
       "      <td>00002433111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>809874</td>\n",
       "      <td>4259738</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.962150</td>\n",
       "      <td>23.721790</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Less than a day</td>\n",
       "      <td>f</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>Dato desconocido</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Host greets you\", \"Dishes and silverware\", \"...</td>\n",
       "      <td>00001240742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>866381</td>\n",
       "      <td>4551671</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>23.724430</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Less than a day</td>\n",
       "      <td>t</td>\n",
       "      <td>['email', 'phone', 'work_email']</td>\n",
       "      <td>Dato desconocido</td>\n",
       "      <td>Entire condo</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Coffee\", \"Dishes and silverware\", \"Washer\", ...</td>\n",
       "      <td>00002608390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>886724</td>\n",
       "      <td>4700824</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.997450</td>\n",
       "      <td>23.739730</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Less than a day</td>\n",
       "      <td>f</td>\n",
       "      <td>['email']</td>\n",
       "      <td>Athens, Attica, Greece</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Host greets you\", \"Luggage dropoff allowed\",...</td>\n",
       "      <td>00000052101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>896212</td>\n",
       "      <td>4777984</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>37.988440</td>\n",
       "      <td>23.738450</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Less than a day</td>\n",
       "      <td>t</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>Athens, Attica, Greece</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Host greets you\", \"Coffee\", \"Dishes and silv...</td>\n",
       "      <td>00000206136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>14637</td>\n",
       "      <td>1318251942056598277</td>\n",
       "      <td>25811452</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.979336</td>\n",
       "      <td>23.726354</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-26</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Less than a day</td>\n",
       "      <td>t</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>Dato desconocido</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Coffee\", \"Dishes and silverware\", \"Washer\", ...</td>\n",
       "      <td>00003108542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>14638</td>\n",
       "      <td>1318276742106864141</td>\n",
       "      <td>666320836</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.992753</td>\n",
       "      <td>23.700000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Less than a day</td>\n",
       "      <td>f</td>\n",
       "      <td>['phone']</td>\n",
       "      <td>Dato desconocido</td>\n",
       "      <td>Entire condo</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Heating - split type ductless system\", \"Coff...</td>\n",
       "      <td>00002888548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>14639</td>\n",
       "      <td>1318307768558324736</td>\n",
       "      <td>221534605</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>37.983118</td>\n",
       "      <td>23.756604</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Less than a day</td>\n",
       "      <td>f</td>\n",
       "      <td>['email', 'phone', 'work_email']</td>\n",
       "      <td>Athina, Greece</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"TV\", \"Hair dryer\", \"Refrigerator\", \"Washer \\...</td>\n",
       "      <td>00002764099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14640</th>\n",
       "      <td>14640</td>\n",
       "      <td>1318405788507138933</td>\n",
       "      <td>650411545</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.984651</td>\n",
       "      <td>23.735136</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Less than a day</td>\n",
       "      <td>f</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>Dato desconocido</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Coffee\", \"Outlet covers\", \"Washer\", \"Dishes ...</td>\n",
       "      <td>00003072289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14641</th>\n",
       "      <td>14641</td>\n",
       "      <td>1318601800941001079</td>\n",
       "      <td>31290848</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>37.968246</td>\n",
       "      <td>23.726156</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Less than a day</td>\n",
       "      <td>f</td>\n",
       "      <td>['email', 'phone', 'work_email']</td>\n",
       "      <td>Athina, Greece</td>\n",
       "      <td>Entire condo</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Heating - split type ductless system\", \"Coff...</td>\n",
       "      <td>00003026761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14642 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                   id    host_id  host_response_rate  \\\n",
       "0               0                27262      37177               100.0   \n",
       "1               1               809874    4259738               100.0   \n",
       "2               2               866381    4551671               100.0   \n",
       "3               3               886724    4700824               100.0   \n",
       "4               4               896212    4777984               100.0   \n",
       "...           ...                  ...        ...                 ...   \n",
       "14637       14637  1318251942056598277   25811452               100.0   \n",
       "14638       14638  1318276742106864141  666320836               100.0   \n",
       "14639       14639  1318307768558324736  221534605               100.0   \n",
       "14640       14640  1318405788507138933  650411545               100.0   \n",
       "14641       14641  1318601800941001079   31290848               100.0   \n",
       "\n",
       "       host_acceptance_rate  host_listings_count  host_total_listings_count  \\\n",
       "0                     100.0                  4.0                       12.0   \n",
       "1                      96.0                  2.0                        2.0   \n",
       "2                      97.0                  1.0                        1.0   \n",
       "3                      99.6                  1.0                        1.0   \n",
       "4                     100.0                 29.0                       50.0   \n",
       "...                     ...                  ...                        ...   \n",
       "14637                 100.0                  3.0                        3.0   \n",
       "14638                  99.6                  2.0                        2.0   \n",
       "14639                  98.0                 53.0                       12.5   \n",
       "14640                  99.6                  1.0                        1.0   \n",
       "14641                 100.0                 11.0                       12.5   \n",
       "\n",
       "        latitude  longitude  accommodates  ...  last_scraped       source  \\\n",
       "0      37.989240  23.700000           2.0  ...    2024-12-25  city scrape   \n",
       "1      37.962150  23.721790           4.0  ...    2024-12-25  city scrape   \n",
       "2      38.000000  23.724430           3.0  ...    2024-12-25  city scrape   \n",
       "3      37.997450  23.739730           2.0  ...    2024-12-25  city scrape   \n",
       "4      37.988440  23.738450           2.0  ...    2024-12-25  city scrape   \n",
       "...          ...        ...           ...  ...           ...          ...   \n",
       "14637  37.979336  23.726354           4.0  ...    2024-12-26  city scrape   \n",
       "14638  37.992753  23.700000           2.0  ...    2024-12-25  city scrape   \n",
       "14639  37.983118  23.756604           2.0  ...    2024-12-25  city scrape   \n",
       "14640  37.984651  23.735136           4.0  ...    2024-12-25  city scrape   \n",
       "14641  37.968246  23.726156           3.0  ...    2024-12-25  city scrape   \n",
       "\n",
       "       host_response_time  host_is_superhost  \\\n",
       "0         Less than a day                  t   \n",
       "1         Less than a day                  f   \n",
       "2         Less than a day                  t   \n",
       "3         Less than a day                  f   \n",
       "4         Less than a day                  t   \n",
       "...                   ...                ...   \n",
       "14637     Less than a day                  t   \n",
       "14638     Less than a day                  f   \n",
       "14639     Less than a day                  f   \n",
       "14640     Less than a day                  f   \n",
       "14641     Less than a day                  f   \n",
       "\n",
       "                     host_verifications           neighbourhood  \\\n",
       "0                    ['email', 'phone']        Dato desconocido   \n",
       "1                    ['email', 'phone']        Dato desconocido   \n",
       "2      ['email', 'phone', 'work_email']        Dato desconocido   \n",
       "3                             ['email']  Athens, Attica, Greece   \n",
       "4                    ['email', 'phone']  Athens, Attica, Greece   \n",
       "...                                 ...                     ...   \n",
       "14637                ['email', 'phone']        Dato desconocido   \n",
       "14638                         ['phone']        Dato desconocido   \n",
       "14639  ['email', 'phone', 'work_email']          Athina, Greece   \n",
       "14640                ['email', 'phone']        Dato desconocido   \n",
       "14641  ['email', 'phone', 'work_email']          Athina, Greece   \n",
       "\n",
       "            property_type        room_type  \\\n",
       "0      Entire rental unit  Entire home/apt   \n",
       "1      Entire rental unit  Entire home/apt   \n",
       "2            Entire condo  Entire home/apt   \n",
       "3      Entire rental unit  Entire home/apt   \n",
       "4      Entire rental unit  Entire home/apt   \n",
       "...                   ...              ...   \n",
       "14637  Entire rental unit  Entire home/apt   \n",
       "14638        Entire condo  Entire home/apt   \n",
       "14639  Entire rental unit  Entire home/apt   \n",
       "14640  Entire rental unit  Entire home/apt   \n",
       "14641        Entire condo  Entire home/apt   \n",
       "\n",
       "                                               amenities      license  \n",
       "0      [\"Heating - split type ductless system\", \"Dish...  00002433111  \n",
       "1      [\"Host greets you\", \"Dishes and silverware\", \"...  00001240742  \n",
       "2      [\"Coffee\", \"Dishes and silverware\", \"Washer\", ...  00002608390  \n",
       "3      [\"Host greets you\", \"Luggage dropoff allowed\",...  00000052101  \n",
       "4      [\"Host greets you\", \"Coffee\", \"Dishes and silv...  00000206136  \n",
       "...                                                  ...          ...  \n",
       "14637  [\"Coffee\", \"Dishes and silverware\", \"Washer\", ...  00003108542  \n",
       "14638  [\"Heating - split type ductless system\", \"Coff...  00002888548  \n",
       "14639  [\"TV\", \"Hair dryer\", \"Refrigerator\", \"Washer \\...  00002764099  \n",
       "14640  [\"Coffee\", \"Outlet covers\", \"Washer\", \"Dishes ...  00003072289  \n",
       "14641  [\"Heating - split type ductless system\", \"Coff...  00003026761  \n",
       "\n",
       "[14642 rows x 51 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificar los valores sin repetirse de una columna\n",
    "unico = np.unique(df['host_response_time'])\n",
    "print(unico)\n",
    "\n",
    "#convertimos una variable categorica  dicotomica\n",
    "df['host_response_time']= df['host_response_time'].replace(['Dato desconocido', 'within a few hours', 'within an hour'], 'Less than a day')\n",
    "df['host_response_time']= df['host_response_time'].replace(['a few days or more', 'within a day'], 'More than a day')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11f867d",
   "metadata": {},
   "source": [
    "### Primer caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9273c0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión: \n",
      "[[2550   72]\n",
      " [1705   66]]\n",
      "\n",
      "precision del modelo: \n",
      "0.4782608695652174\n",
      "\n",
      "exactitud del modelo\n",
      "0.5954928295014796\n",
      "\n",
      "sensibilidad del modelo: \n",
      "0.037267080745341616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independietes para la regresión lineal \n",
    "vars_Indep=df[['minimum_minimum_nights', 'minimum_nights', 'minimum_nights_avg_ntm']]\n",
    "vars_Dep=df[['host_is_superhost']]\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= vars_Indep\n",
    "y= vars_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Se escalan todos los datos : Escalr es como si pasaran los datos a una sola escala en porcentajes, como una regla de tres \n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realuzar el escalamiento de las variables \"X\" tanto en entrenamiento como de prueba utilizaremos:\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred = algoritmo.predict(X_test) #Predecimos los datos de test\n",
    "y_pred\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de confusión: ')\n",
    "print(matriz)\n",
    "print('')\n",
    "\n",
    "#Calculo la precisión de mmodelo\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='binary', pos_label ='t')\n",
    "print('precision del modelo: ')\n",
    "print(precision)\n",
    "print('')\n",
    "\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('exactitud del modelo')\n",
    "print(exactitud)\n",
    "print('')\n",
    "\n",
    "\n",
    "#calculamos la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average='binary', pos_label='t')\n",
    "print('sensibilidad del modelo: ')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde514e2",
   "metadata": {},
   "source": [
    "### Segundo caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85f86f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión: \n",
      "[[4228    0]\n",
      " [ 165    0]]\n",
      "\n",
      "precision del modelo: \n",
      "0.0\n",
      "\n",
      "exactitud del modelo\n",
      "0.9624402458456636\n",
      "\n",
      "sensibilidad del modelo: \n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independietes para la regresión lineal \n",
    "vars_Indep=df[['accommodates', 'review_scores_rating', 'bedrooms']]\n",
    "vars_Dep=df[['host_response_time']]\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= vars_Indep\n",
    "y= vars_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Se escalan todos los datos : Escalr es como si pasaran los datos a una sola escala en porcentajes, como una regla de tres \n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realuzar el escalamiento de las variables \"X\" tanto en entrenamiento como de prueba utilizaremos:\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred = algoritmo.predict(X_test) #Predecimos los datos de test\n",
    "y_pred\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de confusión: ')\n",
    "print(matriz)\n",
    "print('')\n",
    "\n",
    "#Calculo la precisión de mmodelo\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='binary', pos_label ='More than a day')\n",
    "print('precision del modelo: ')\n",
    "print(precision)\n",
    "print('')\n",
    "\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('exactitud del modelo')\n",
    "print(exactitud)\n",
    "print('')\n",
    "\n",
    "\n",
    "#calculamos la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average='binary', pos_label='More than a day')\n",
    "print('sensibilidad del modelo: ')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df41b477",
   "metadata": {},
   "source": [
    "### Tercer caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4026cbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión: \n",
      "[[4105    0]\n",
      " [ 288    0]]\n",
      "\n",
      "precision del modelo: \n",
      "0.0\n",
      "\n",
      "exactitud del modelo\n",
      "0.9344411563851582\n",
      "\n",
      "sensibilidad del modelo: \n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independietes para la regresión lineal \n",
    "vars_Indep=df[['minimum_nights_avg_ntm', 'maximum_minimum_nights', 'host_listings_count']]\n",
    "vars_Dep=df[['source']]\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= vars_Indep\n",
    "y= vars_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Se escalan todos los datos : Escalr es como si pasaran los datos a una sola escala en porcentajes, como una regla de tres \n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realuzar el escalamiento de las variables \"X\" tanto en entrenamiento como de prueba utilizaremos:\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred = algoritmo.predict(X_test) #Predecimos los datos de test\n",
    "y_pred\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de confusión: ')\n",
    "print(matriz)\n",
    "print('')\n",
    "\n",
    "#Calculo la precisión de mmodelo\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='binary', pos_label ='previous scrape')\n",
    "print('precision del modelo: ')\n",
    "print(precision)\n",
    "print('')\n",
    "\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('exactitud del modelo')\n",
    "print(exactitud)\n",
    "print('')\n",
    "\n",
    "\n",
    "#calculamos la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average='binary', pos_label='previous scrape')\n",
    "print('sensibilidad del modelo: ')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d60256e",
   "metadata": {},
   "source": [
    "### Cuarto caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32a24b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(4.65), np.float64(5.0)]\n",
      "[4.64 4.87 5.1 ]\n"
     ]
    }
   ],
   "source": [
    "#Obtenmos el limite superiro y el limite inferior de la columna objetivo\n",
    "\n",
    "max = df['review_scores_rating'].max()\n",
    "min=df['review_scores_rating'].min()\n",
    "limites = [min,max]\n",
    "print(limites)\n",
    "\n",
    "#Categorización de varibales\n",
    "#declaramos 2 intervalos\n",
    "\n",
    "intervalos=np.linspace(4.64, 5.1,3)\n",
    "print(intervalos)\n",
    "\n",
    "#Creamos las categorias\n",
    "categorias = ['Bad score', 'Good score']\n",
    "\n",
    "#Finalmente creamos las categorias en la columa numerica\n",
    "df['review_scores_rating'] = pd.cut(x=df['review_scores_rating'], bins = intervalos, labels= categorias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db8061bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión: \n",
      "[[   0 1082]\n",
      " [   0 3311]]\n",
      "\n",
      "precision del modelo: \n",
      "0.0\n",
      "\n",
      "exactitud del modelo\n",
      "0.753699066697018\n",
      "\n",
      "sensibilidad del modelo: \n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independietes para la regresión lineal \n",
    "vars_Indep=df[['minimum_nights_avg_ntm', 'maximum_minimum_nights', 'host_listings_count']]\n",
    "vars_Dep=df[['review_scores_rating']]\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= vars_Indep\n",
    "y= vars_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Se escalan todos los datos : Escalr es como si pasaran los datos a una sola escala en porcentajes, como una regla de tres \n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realuzar el escalamiento de las variables \"X\" tanto en entrenamiento como de prueba utilizaremos:\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred = algoritmo.predict(X_test) #Predecimos los datos de test\n",
    "y_pred\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de confusión: ')\n",
    "print(matriz)\n",
    "print('')\n",
    "\n",
    "#Calculo la precisión de mmodelo\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='binary', pos_label ='Bad score')\n",
    "print('precision del modelo: ')\n",
    "print(precision)\n",
    "print('')\n",
    "\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('exactitud del modelo')\n",
    "print(exactitud)\n",
    "print('')\n",
    "\n",
    "\n",
    "#calculamos la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average='binary', pos_label='Bad score')\n",
    "print('sensibilidad del modelo: ')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb44aa17",
   "metadata": {},
   "source": [
    "### Quinto caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d08e4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(35.0), np.float64(90.0)]\n",
      "[34.9 62.5 90.1]\n"
     ]
    }
   ],
   "source": [
    "#Obtenmos el limite superiro y el limite inferior de la columna objetivo\n",
    "\n",
    "max = df['availability_90'].max()\n",
    "min=df['availability_90'].min()\n",
    "limites = [min,max]\n",
    "print(limites)\n",
    "\n",
    "#Categorización de varibales\n",
    "#declaramos 2 intervalos\n",
    "\n",
    "intervalos=np.linspace(34.9, 90.1,3)\n",
    "print(intervalos)\n",
    "\n",
    "#Creamos las categorias\n",
    "categorias = ['Baja demanda', 'Alta demanda']\n",
    "\n",
    "#Finalmente creamos las categorias en la columa numerica\n",
    "df['availability_90'] = pd.cut(x=df['availability_90'], bins = intervalos, labels= categorias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca213fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión: \n",
      "[[3727    0]\n",
      " [ 666    0]]\n",
      "\n",
      "precision del modelo: \n",
      "0.0\n",
      "\n",
      "exactitud del modelo\n",
      "0.8483951741406783\n",
      "\n",
      "sensibilidad del modelo: \n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independietes para la regresión lineal \n",
    "vars_Indep=df[['minimum_nights_avg_ntm', 'maximum_minimum_nights', 'host_listings_count']]\n",
    "vars_Dep=df[['availability_90']]\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= vars_Indep\n",
    "y= vars_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Se escalan todos los datos : Escalr es como si pasaran los datos a una sola escala en porcentajes, como una regla de tres \n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realuzar el escalamiento de las variables \"X\" tanto en entrenamiento como de prueba utilizaremos:\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred = algoritmo.predict(X_test) #Predecimos los datos de test\n",
    "y_pred\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de confusión: ')\n",
    "print(matriz)\n",
    "print('')\n",
    "\n",
    "#Calculo la precisión de mmodelo\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='binary', pos_label ='Baja demanda')\n",
    "print('precision del modelo: ')\n",
    "print(precision)\n",
    "print('')\n",
    "\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('exactitud del modelo')\n",
    "print(exactitud)\n",
    "print('')\n",
    "\n",
    "\n",
    "#calculamos la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average='binary', pos_label='Baja demanda')\n",
    "print('sensibilidad del modelo: ')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42728c2d",
   "metadata": {},
   "source": [
    "### Sexto caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8c9c3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(4.66), np.float64(5.0)]\n",
      "[4.65  4.875 5.1  ]\n"
     ]
    }
   ],
   "source": [
    "#Obtenmos el limite superiro y el limite inferior de la columna objetivo\n",
    "\n",
    "max = df['review_scores_cleanliness'].max()\n",
    "min=df['review_scores_cleanliness'].min()\n",
    "limites = [min,max]\n",
    "print(limites)\n",
    "\n",
    "#Categorización de varibales\n",
    "#declaramos 2 intervalos\n",
    "\n",
    "intervalos=np.linspace(4.65, 5.1,3)\n",
    "print(intervalos)\n",
    "\n",
    "#Creamos las categorias\n",
    "categorias = ['Pocas reseñas', 'Muchas reseñas']\n",
    "\n",
    "#Finalmente creamos las categorias en la columa numerica\n",
    "df['review_scores_cleanliness'] = pd.cut(x=df['review_scores_cleanliness'], bins = intervalos, labels= categorias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3919a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión: \n",
      "[[3256   94]\n",
      " [ 943  100]]\n",
      "\n",
      "precision del modelo: \n",
      "0.5154639175257731\n",
      "\n",
      "exactitud del modelo\n",
      "0.763942636011837\n",
      "\n",
      "sensibilidad del modelo: \n",
      "0.09587727708533078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independietes para la regresión lineal \n",
    "vars_Indep=df[['reviews_per_month', 'review_scores_checkin', 'number_of_reviews']]\n",
    "vars_Dep=df[['review_scores_cleanliness']]\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= vars_Indep\n",
    "y= vars_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Se escalan todos los datos : Escalr es como si pasaran los datos a una sola escala en porcentajes, como una regla de tres \n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realuzar el escalamiento de las variables \"X\" tanto en entrenamiento como de prueba utilizaremos:\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred = algoritmo.predict(X_test) #Predecimos los datos de test\n",
    "y_pred\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de confusión: ')\n",
    "print(matriz)\n",
    "print('')\n",
    "\n",
    "#Calculo la precisión de mmodelo\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='binary', pos_label ='Pocas reseñas')\n",
    "print('precision del modelo: ')\n",
    "print(precision)\n",
    "print('')\n",
    "\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('exactitud del modelo')\n",
    "print(exactitud)\n",
    "print('')\n",
    "\n",
    "\n",
    "#calculamos la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average='binary', pos_label='Pocas reseñas')\n",
    "print('sensibilidad del modelo: ')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a86a6",
   "metadata": {},
   "source": [
    "### Séptimo caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bddd44d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(25.0), np.float64(175.0)]\n",
      "[ 24.9 100.  175.1]\n"
     ]
    }
   ],
   "source": [
    "#Obtenmos el limite superiro y el limite inferior de la columna objetivo\n",
    "\n",
    "max = df['price'].max()\n",
    "min=df['price'].min()\n",
    "limites = [min,max]\n",
    "print(limites)\n",
    "\n",
    "#Categorización de varibales\n",
    "#declaramos 2 intervalos\n",
    "\n",
    "intervalos=np.linspace(24.9, 175.1,3)\n",
    "print(intervalos)\n",
    "\n",
    "#Creamos las categorias\n",
    "categorias = ['Precios bajos', 'Precios altos']\n",
    "\n",
    "#Finalmente creamos las categorias en la columa numerica\n",
    "df['price'] = pd.cut(x=df['price'], bins = intervalos, labels= categorias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb4e5c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión: \n",
      "[[   0  713]\n",
      " [   0 3680]]\n",
      "\n",
      "precision del modelo: \n",
      "0.0\n",
      "\n",
      "exactitud del modelo\n",
      "0.837696335078534\n",
      "\n",
      "sensibilidad del modelo: \n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independietes para la regresión lineal \n",
    "vars_Indep=df[['availability_30', 'maximum_minimum_nights', 'host_listings_count']]\n",
    "vars_Dep=df[['price']]\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= vars_Indep\n",
    "y= vars_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Se escalan todos los datos : Escalr es como si pasaran los datos a una sola escala en porcentajes, como una regla de tres \n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realuzar el escalamiento de las variables \"X\" tanto en entrenamiento como de prueba utilizaremos:\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred = algoritmo.predict(X_test) #Predecimos los datos de test\n",
    "y_pred\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de confusión: ')\n",
    "print(matriz)\n",
    "print('')\n",
    "\n",
    "#Calculo la precisión de mmodelo\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='binary', pos_label ='Precios altos')\n",
    "print('precision del modelo: ')\n",
    "print(precision)\n",
    "print('')\n",
    "\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('exactitud del modelo')\n",
    "print(exactitud)\n",
    "print('')\n",
    "\n",
    "\n",
    "#calculamos la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average='binary', pos_label='Precios altos')\n",
    "print('sensibilidad del modelo: ')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b86c6ab",
   "metadata": {},
   "source": [
    "### Octavo caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "897291c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(1.0), np.float64(3.0)]\n",
      "[0.9 2.  3.1]\n"
     ]
    }
   ],
   "source": [
    "#Obtenmos el limite superiro y el limite inferior de la columna objetivo\n",
    "\n",
    "max = df['beds'].max()\n",
    "min=df['beds'].min()\n",
    "limites = [min,max]\n",
    "print(limites)\n",
    "\n",
    "#Categorización de varibales\n",
    "#declaramos 2 intervalos\n",
    "\n",
    "intervalos=np.linspace(0.9, 3.1,3)\n",
    "print(intervalos)\n",
    "\n",
    "#Creamos las categorias\n",
    "categorias = ['1 cama', 'más de 2 camas']\n",
    "\n",
    "#Finalmente creamos las categorias en la columa numerica\n",
    "df['beds'] = pd.cut(x=df['beds'], bins = intervalos, labels= categorias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30eaf82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión: \n",
      "[[3781    0]\n",
      " [ 612    0]]\n",
      "\n",
      "precision del modelo: \n",
      "0.0\n",
      "\n",
      "exactitud del modelo\n",
      "0.8606874573184612\n",
      "\n",
      "sensibilidad del modelo: \n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independietes para la regresión lineal \n",
    "vars_Indep=df[['availability_30', 'maximum_minimum_nights', 'host_listings_count']]\n",
    "vars_Dep=df[['beds']]\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= vars_Indep\n",
    "y= vars_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Se escalan todos los datos : Escalr es como si pasaran los datos a una sola escala en porcentajes, como una regla de tres \n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realuzar el escalamiento de las variables \"X\" tanto en entrenamiento como de prueba utilizaremos:\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred = algoritmo.predict(X_test) #Predecimos los datos de test\n",
    "y_pred\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de confusión: ')\n",
    "print(matriz)\n",
    "print('')\n",
    "\n",
    "#Calculo la precisión de mmodelo\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='binary', pos_label ='más de 2 camas')\n",
    "print('precision del modelo: ')\n",
    "print(precision)\n",
    "print('')\n",
    "\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('exactitud del modelo')\n",
    "print(exactitud)\n",
    "print('')\n",
    "\n",
    "\n",
    "#calculamos la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average='binary', pos_label='más de 2 camas')\n",
    "print('sensibilidad del modelo: ')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255823b",
   "metadata": {},
   "source": [
    "###  Noveno caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffeccffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(96.0), np.float64(100.0)]\n",
      "[ 95.9  98.  100.1]\n"
     ]
    }
   ],
   "source": [
    "#Obtenmos el limite superiro y el limite inferior de la columna objetivo\n",
    "\n",
    "max = df['host_acceptance_rate'].max()\n",
    "min=df['host_acceptance_rate'].min()\n",
    "limites = [min,max]\n",
    "print(limites)\n",
    "\n",
    "#Categorización de varibales\n",
    "#declaramos 2 intervalos\n",
    "\n",
    "intervalos=np.linspace(95.9, 100.1,3)\n",
    "print(intervalos)\n",
    "\n",
    "#Creamos las categorias\n",
    "categorias = ['Media alta aceptación', 'Alta aceptación']\n",
    "\n",
    "#Finalmente creamos las categorias en la columa numerica\n",
    "df['host_acceptance_rate'] = pd.cut(x=df['host_acceptance_rate'], bins = intervalos, labels= categorias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74477a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión: \n",
      "[[4031    0]\n",
      " [ 362    0]]\n",
      "\n",
      "precision del modelo: \n",
      "0.0\n",
      "\n",
      "exactitud del modelo\n",
      "0.9175961757341224\n",
      "\n",
      "sensibilidad del modelo: \n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independietes para la regresión lineal \n",
    "vars_Indep=df[['availability_30', 'maximum_minimum_nights', 'host_listings_count']]\n",
    "vars_Dep=df[['host_acceptance_rate']]\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= vars_Indep\n",
    "y= vars_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Se escalan todos los datos : Escalr es como si pasaran los datos a una sola escala en porcentajes, como una regla de tres \n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realuzar el escalamiento de las variables \"X\" tanto en entrenamiento como de prueba utilizaremos:\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred = algoritmo.predict(X_test) #Predecimos los datos de test\n",
    "y_pred\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de confusión: ')\n",
    "print(matriz)\n",
    "print('')\n",
    "\n",
    "#Calculo la precisión de mmodelo\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='binary', pos_label ='Media alta aceptación')\n",
    "print('precision del modelo: ')\n",
    "print(precision)\n",
    "print('')\n",
    "\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('exactitud del modelo')\n",
    "print(exactitud)\n",
    "print('')\n",
    "\n",
    "\n",
    "#calculamos la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average='binary', pos_label='Media alta aceptación')\n",
    "print('sensibilidad del modelo: ')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e114445",
   "metadata": {},
   "source": [
    "### Décimo caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c08a6b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(1.0), np.float64(38.0)]\n",
      "[ 0.9 19.5 38.1]\n"
     ]
    }
   ],
   "source": [
    "#Obtenmos el limite superiro y el limite inferior de la columna objetivo\n",
    "\n",
    "max = df['calculated_host_listings_count'].max()\n",
    "min=df['calculated_host_listings_count'].min()\n",
    "limites = [min,max]\n",
    "print(limites)\n",
    "\n",
    "#Categorización de varibales\n",
    "#declaramos 2 intervalos\n",
    "\n",
    "intervalos=np.linspace(0.9, 38.1,3)\n",
    "print(intervalos)\n",
    "\n",
    "#Creamos las categorias\n",
    "categorias = ['Pocas propiedades', 'Varias propiedades']\n",
    "\n",
    "#Finalmente creamos las categorias en la columa numerica\n",
    "df['calculated_host_listings_count'] = pd.cut(x=df['calculated_host_listings_count'], bins = intervalos, labels= categorias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebcaf6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión: \n",
      "[[3820  169]\n",
      " [ 312   92]]\n",
      "\n",
      "precision del modelo: \n",
      "0.3524904214559387\n",
      "\n",
      "exactitud del modelo\n",
      "0.8905076257682677\n",
      "\n",
      "sensibilidad del modelo: \n",
      "0.22772277227722773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independietes para la regresión lineal \n",
    "vars_Indep=df[['availability_30', 'maximum_minimum_nights', 'host_listings_count']]\n",
    "vars_Dep=df[['calculated_host_listings_count']]\n",
    "\n",
    "#Redefinimos las variables\n",
    "X= vars_Indep\n",
    "y= vars_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=None)\n",
    "\n",
    "#Se escalan todos los datos : Escalr es como si pasaran los datos a una sola escala en porcentajes, como una regla de tres \n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realuzar el escalamiento de las variables \"X\" tanto en entrenamiento como de prueba utilizaremos:\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "y_pred = algoritmo.predict(X_test) #Predecimos los datos de test\n",
    "y_pred\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de confusión: ')\n",
    "print(matriz)\n",
    "print('')\n",
    "\n",
    "#Calculo la precisión de mmodelo\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='binary', pos_label ='Varias propiedades')\n",
    "print('precision del modelo: ')\n",
    "print(precision)\n",
    "print('')\n",
    "\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('exactitud del modelo')\n",
    "print(exactitud)\n",
    "print('')\n",
    "\n",
    "\n",
    "#calculamos la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average='binary', pos_label='Varias propiedades')\n",
    "print('sensibilidad del modelo: ')\n",
    "print(sensibilidad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
